% コンパイル：
% extractbb img/*.png
% platex soturon.tex
% pbibtex soturon
% platex soturon.tex
% dvipdfmx soturon

\documentclass{jsarticle}

\usepackage[dvipdfmx]{graphicx}
\usepackage{url}
\usepackage{slashbox}

%\usepackage{amsmath}
%\usepackage{txfonts}

\newcommand{\todayd}{\the\year--\the\month--\the\day}

\title{}
\date{\today}
%\affiliation{総合情報学科 メディア情報学コース}
%\supervisor{橋山智訓 准教授}
%\studentid{1310163}
\author{柴澤弘樹}
%\headtitle{平成28年度 総合情報学科 卒業論文中間発表}
\title{ぷよぷよの連鎖構築AIに関する研究}

\begin{document}
\maketitle

\part{序論} \setcounter{section}{0}
\section{背景}
\subsection{ゲームを取り巻く状況}
%遊びとコンピュータゲームの歴史
我々人類は、遊びと共に生きている。ホイジンガは「ホモ・ルーデンス」の中で、遊びが文化よりも古いものであると述べている\cite{homo}。現在遊ばれているコンピュータゲームもまた、遊びの一種といえる。藤田による調査\cite{huzita1,huzita2,huzita3}の中で、コンピュータゲームの一般への普及は、1980年代からであったことが述べられている。

%スマフォによる一般へのゲーム普及、e-sportの市場拡大
現在では、スマートフォンの普及と共にゲームプレイヤーがさらに増えている。ファミ通ゲーム白書2016\cite{famitu}により、アプリゲームを含むゲーム市場の拡大が示されている。さらには、eスポーツとして、ゲームでプレイヤー同士が競う大会も多く開催されている。大会やプロプレイヤーにはスポンサーがつき、世界規模の市場となっている\cite{e-sports}。これらの市場は、今後もますますの成長が期待されている。

%ネット対戦、AIは対戦相手として不足
このような背景の中で、遊びとしてのゲームはより身近なものになっている。様々なハードウェアでインターネットを介した協力、対戦プレイが可能となっており、遠く離れたプレイヤー同士で同じゲームをプレイすることも当然のこととなった。それによって、遊び相手として人間が一般的になり、AIを相手に長時間遊ぶゲームは限られたものとなってきている。ゲームAI技術は著しい発展を遂げてきたものの、遊び相手としては未だ向上の余地があるといえる。

%なぜAIである必要があるか？　マッチング、練習、環境、対人への抵抗
インターネットを介した対人プレイにおいては、以下のような問題が挙げられる。
\begin{itemize}
\item 対応した環境の必要性
\item 十分なプレイ人口の必要性
\item プレイスキルを考慮したマッチング
\item 気兼ねない相手とはならない
\item 対人への抵抗感
\end{itemize}
以下、簡単に説明する。環境は、ゲームのハード、ソフト両面で整っている必要がある。インターネット環境の不足や、対応していないゲームではオンラインプレイが不可能となる。プレイ人口は、時間や発売からの経過日数などの影響を受ける。十分にプレイヤーが揃わなければ、マッチングができない。それに付随し、プレイスキルのバランスを考慮したマッチメイキングも必要となる。また相手が人間であるため、他プレイヤーを無視した勝手なふるまいが全くできない問題もある。ゲームを楽しんだり練習したりするため、あえて無駄な動きや非効率な行為をすることができないのである。心情的に、他人とゲームをプレイすることを忌避するプレイヤーも一定数いると考えられる。

以上の問題の通り、遊び相手としての人間が、必ずしも適しているとはいえない場面が存在する。このとき、ゲームAIは一つの解決策となる。そのため、プレイヤーに楽しさを提供する手法を研究し、遊び相手としてのAIを実現することに一定の意義があると考えられる。

\subsection{ゲームAIの現状}
%学術研究、コンペティション、強いAI
これまでのゲームAIの研究は、強いAIを目指したものだった。IEEE CIGをはじめとするAIコンペティション\cite{cig}や、人間との戦いによって強さが競われてきた。特に盤上ゲームでは、1997年のDeep Blue、2013のponannza、そして2015年のAlphaGo\cite{alphaGo}が、それぞれプロ棋士に初勝利を収めた。いまやAIは、人間と同等以上の強さをもつようになったと言える。つまり、AIの強さにおける研究は、一定の成果が得られたと言われるようになってきている。

%探索アルゴリズム、モンテカルロ法
強いAIを求めるこれまでの研究は、探索アルゴリズムの研究であったという見方ができる。完全情報ゲームの着手に評価を与え、最適解を探索する手法が様々提案されてきた。着手に対しどのような評価を与え、計算資源の中でいかに効率よく探索を行うかが問題だったのである。AlphGoでは、ディープニューラルネットワークによる評価と、モンテカルロ木探索によってそれらの問題を解決した。これらの手法は、AIの挙動がブラックボックスとなり、全容の理解が困難となる問題がある。その一方で汎用性が高く、様々に応用されている\cite{NE, monte}。完全情報ゲームに関しては十分な成果が得られたことから、今後の強さに関する研究は、不完全情報ゲームやGeneral Game Playing(GGP)へ移行してゆくと思われる。

%実際の恩恵、ユーザエクスペリエンスの向上を目的としたAI： miyake, yan_panorama
以上で述べた通り、これまでのゲームAIは、強さや性能を評価する場として、ゲームを用いていたにすぎない。人間プレイヤーのゲーム体験を向上させる域には達していないのである。しかし、強さが十分な領域に達したことで、今後はユーザエクスペリエンスを考慮したAIの研究が活発化してゆくといわれている\cite{miyake_genzai, ikeda}。YannakakisはゲームAI研究の分野を以下の10個に分類した\cite{yan_panorama}。
\begin{enumerate}
\item Non-player character(NPC) behavior learning
\item Search and planning
\item Player modeling
\item Games as AI benchmarks
\item Procedural content generation
\item Computational narrative
\item Believable agents
\item AI-assisted game design
\item Gneral game AI
\item AI in commercial games
\end{enumerate}
競争としてのみではなく、デザイナーやプレイヤーのことを考慮したAI研究がなされていることが分かる。ゲームの遊びや楽しさという側面が、今後ますます注目されてゆくことが予想される。


\section{目的}
%ぷよぷよ：e-sportsの実績、技術レベルの幅広さ、AIがダメダメ、探索問題としての難しさ
本研究では、人を楽しませる相手としてのAIを構成する手法を提案することを、最終目的とする。特にパズルゲームの「ぷよぷよ」を対象とし、その対戦AIを実装する。「ぷよぷよ」は、以下のような特徴をもつ。
\begin{itemize}
\item 長年にわたって親しまれているゲームである
\item 大会やe-sportsでの対戦実績がある
\item プレイヤースキルの幅が非常に広い
\item 対戦用AIの性能が不十分である
\item 探索問題として難しい題材である
\end{itemize}
「ぷよぷよ」は長年にわたって、対戦ゲームとして親しまれてきた。それにも関わらず、対戦相手としてのAIは未だ不十分である。また不完全情報ゲームであり、探索問題としても課題が残されている。以上の観点から、「ぷよぷよ」のAIが研究対象として意義をもつと考えられる。

%人を楽しませる対戦AI：連鎖、戦術
%連鎖構築が不十分：連鎖数、柔軟性、リアルタイム性
対戦における「ぷよぷよ」のプレイでは、連鎖構築や戦術が重要となる。上級者のプレイでは、十分な威力の連鎖を保持しつつ、相手を妨害したり、相手の妨害を阻止したりする戦術が用いられている。現状のAIでは、どちらも不十分である。この解決のためにはまず、より基本的な行為である、連鎖構築を満足に行えなければならない。対戦中での連鎖構築は、連鎖数、柔軟性、リアルタイム性の3点を満足することが大切であると考えられる。本研究では、この3点を満たす連鎖構築アルゴリズムを実現することを目的とする。

%解決すべき課題%難しさ、技術的課題：
%・スコア増加の長期的視点（NG:1手で消去, OK:3手で+1連鎖）
%・ランダム性とおじゃまによる先読みの難しさ
%・色の可換性、ツモ順によるパターン化の難しさ
%・累乗オーダでの計算量
%・リアルタイムの制約
「ぷよぷよ」の連鎖構築AIの実装にあたり、技術的課題は以下に挙げられる。
\begin{itemize}
\item 長期的視点に基づく探索
\item 不完全情報と妨害による先読みの難しさ
\item 完成形のパターン化の難しさ
\item 計算量の膨大さとリアルタイムの制約
\end{itemize}
大きな連鎖数を確保するためには、長期的視点に基づいてぷよの配置を決定する必要がある。同じ一手であっても、すぐに連鎖の威力を補強できる手よりも、数手先で連鎖数を増やすための布石とする手の方が有効である。このために先読みが必要になるが、配される手がランダムであること、リアルタイムに相手からの妨害があることを考慮すると、その可能性が膨大になる。さらにはそのランダム性から、連鎖の完成形をあらかじめ想定しておくことが、大きな手間となる。配された手から完成形を組みかえるような、柔軟性ある連鎖構築が望ましいのはそのためである。最後に、ぷよは操作をしなくとも自由落下するため、配置の決定に時間的制約がある。以上のような課題を解決する手法の研究が、本稿の目的である。

\section{本論文の構成}


\part{ぷよぷよについて} \setcounter{section}{0}
\section{発売タイトル}
最初の「ぷよぷよ」は、コンパイルより1991年に発売された。当初の「ぷよぷよ」には相殺がなく、1994年の「ぷよぷよ通」によってはじめて導入された。以降のシリーズの基本形はこの「ぷよぷよ通」であるとされ、AC（アーケード）版は現在でも大会で利用される。その後もシリーズは続いたものの売り上げは振るわず、コンパイルは経営破綻に陥った。

2003年の「ぷよぷよフィーバー」以降はセガによってぷよぷよが発売されている。2004年のWindows版「ぷよぷよフィーバー」で、初の公式ネット対戦が可能となった。対戦ルールは「クラシックルール」（実質的な「通」ルール）と「フィーバールール」が搭載されていた。
その後も家庭用ゲーム機や携帯ゲーム機に向けて複数のタイトルが発売されている。2014年には「ぷよぷよ」と同じく落ちものパズルゲームの「テトリス」を組み合わせた、「ぷよぷよテトリス」が発売された。「テトリス」と「ぷよぷよ」の対戦が可能となるなど、異色の作品であった。「ぷよぷよ」のルールは、主に「ぷよぷよ通」に準拠したものとなっている。最新作は2016年発売の「ぷよぷよクロニクル」で、インターネット対戦では「スキルバトル」「ぷよぷよ通」「ぷよぷよフィーバー」の3種類のルールがプレイできる。

その他、「ぷよぷよ!!クエスト」や「なぞぷよ」などの派生作品が、スマートフォン向けアプリなどで発売されている。これらはグラフィックやキャラクター、4つつながると消える点などは踏襲しているものの、対戦要素が無くシステムも異なるため、従来のぷよぷよシリーズとは別のゲームであるといえる。

シリーズ全体を通し、特に対戦において「ぷよぷよ通」が基準となっていることが読み取れる。これまでに様々な新ルール搭載のタイトルが発売されてきたものの、「通」のルールに置き換わるものは未だ現れていない。そこで本稿でも「ぷよぷよ通」のルールに準拠し、以下の「ぷよぷよ」に関する研究を進める。

\section{ルール}
本研究で扱う、「ぷよぷよ通」の基本的なルールと用語について説明する。

%フィールド、ツモ
%ツモ：ペア、ネクスト・ネクネク、4色、自分と相手は同一、
\subsection{フィールドとぷよ}
\begin{figure}[hbt]
  \begin{center}
  \includegraphics[height=10cm]{img/field.png}
  \caption{ぷよぷよのゲーム画面の概略} \label{fig:field}
\end{center}
\end{figure}

ぷよぷよのゲーム画面の概略図を、図\ref{fig:field}に示す。ぷよぷよのフィールドは、横6列$\times$縦12段が可視範囲である。以下、列数は左から数えたもの、段数は下から数えたものとする。配置するブロックは「ぷよ」と呼ばれる。3列目、12段目のマスにぷよを置くと窒息であり、負け（ばたんきゅ～）となる。また、実際にはフィールドに13段目があり、12段目にぷよがある状態で「回し」という操作技術を用いて、視覚範囲外へぷよを設置できる。13段目のぷよは可視できない状態で繋がったり消えたりすることはなく、12段目以下のぷよを消し、落下させることで連鎖に寄与する。

配石は2つのぷよがペアで現れ、これをツモという。ツモは落下中の物のほかに、次のツモ（ネクストぷよ）と次の次のツモ（ネクネクぷよ）が予め表示される。ぷよは複数の色から成り、対戦では最大4色が標準である。すなわち、4色のぷよが2つずつ現れることから、ツモは全16通りが存在する。対戦におけるツモ順は各プレイヤーで同一である。ツモの配色はランダムであり、表示される手数に上限があることから、配石に関する情報の不完全性が認められる。

ツモは3列目の13段目と12段目に現れ、自然に落下してゆく。落下中のツモは横移動と4方向回転ができるため、すでに埋まっていない限りは任意の列、あるいはそれと隣り合った列に配置できる。ぷよの設置の際は、下段に空白を認めない。下に空洞がある場合、それより上のぷよは全て下に落下する。よって、段差がある隣り合った2列に対しツモを横向きに置いた場合、片方のぷよが落下する。これを「ちぎる」という（図\ref{fig:tigiri}参照）。ツモの配置方法の選択は、異なる色の場合22通り、同色（ゾロ）の場合11通りとなる。
\begin{figure}[hbt]
  \begin{center}
  \includegraphics[height=7cm]{img/tigiri.png}
  \caption{「ちぎり」の発生の様子} \label{fig:tigiri}
\end{center}
\end{figure}

%消去、連鎖
\subsection{ぷよの消去と連鎖}
置かれた色ぷよは、上下左右に隣接したマスの同色ぷよと連結する。ここで色ぷよとは、後述の「おじゃまぷよ」ではない、ツモによって配されたぷよのことである。接続数が4以上となったぷよは、その時点ですべて消える。ぷよが消えたマスは空白となるが、その上部に別のぷよが存在する場合には、その落下により空白は埋められる。

\begin{figure}[hbt]
  \begin{center}
  \includegraphics[height=6cm]{img/rensa.png}
  \caption{「連鎖」の発生の様子} \label{fig:rensa}
\end{center}
\end{figure}

ぷよが消えた後の落下により、さらに4つ以上接続されたぷよが現れた場合には、連続でぷよの消去が発生する（図\ref{fig:rensa}参照）。これを連鎖という。連続での消去がn回発生した際にはn連鎖となる。ぷよが消えるために最低4つを必要とし、フィールドは全78マスであるから、最大連鎖数は19連鎖である。また、連鎖を発動させるためにぷよを消去することを、「発火」という。

発火時には3列目12段目にもぷよを設置することができ、即座にはゲームオーバーとならない。ぷよの消去および連鎖の発生中には、新たなツモは発生せず、プレイヤーは操作ができない。連鎖がすべて終了した後に、操作可能となる。この時、3列目12段目にぷよが残っていると、その時点でゲームオーバーとなる。

%予告ぷよ、相殺、降るタイミング
%スコア
\subsection{スコアとおじゃまぷよ}
ゲーム中には各プレイヤーのスコアが計算される。スコアは下キーによるぷよの落下操作時と、ぷよの消去および連鎖時、全消し時に増加し、1ゲーム中に減少することはない。落下操作時には、1マスにつき1点が加算される。全消しの際には2100点が加算される。n連鎖におけるスコアは、式\ref{fo:score}で算出できる。

\begin{eqnarray} \label{fo:score}
score & = & \sum_{i=1}^{n}(score_{i}) \nonumber \\
& = & \sum_{i=1}^{n}(delPuyo_{i} \times 10 \times bonus_{i})
\end{eqnarray}
ここで、$score$は発動した連鎖の合計スコア、$score_{i}$は$i$連鎖目のみのスコア、$delPuyo_{i}$は$i$連鎖目で消えたぷよの数、$bonus_{i}$は$i$連鎖目でのボーナス係数を表す。

ボーナスは、以下の3つのボーナスの総和で表される。
\begin{itemize}
\item 多色ボーナス：同時に消した色の数によるボーナス
\item 連結ボーナス：消したぷよの接続数によるボーナス
\item 連鎖ボーナス：連鎖数によるボーナス
\end{itemize}
それぞれのボーナス値を、表\ref{tab:color_bonus}、表\ref{tab:connect_bonus}、表\ref{tab:chain_bonus}に示す。ただし、ボーナスの総和が0の時には、値を1とする。

\begin{table}[htb]
\begin{center}
\caption{多色ボーナス} \label{tab:color_bonus}
\begin{tabular}{|l|r|r|r|r|} \hline
色数 & 1 & 2 & 3 & 4\\ \hline
ボーナス & 0 & 6 & 12 & 24\\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[htb]
\begin{center}
\caption{連結ボーナス} \label{tab:connect_bonus}
\begin{tabular}{|l|r|r|r|r|r|r|r|r|} \hline
連結数 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11以上\\ \hline
ボーナス & 0 & 2 & 3 & 4 & 5 & 6 & 7 & 10\\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[htb]
\begin{center}
\caption{連鎖ボーナス} \label{tab:chain_bonus}
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|} \hline
連鎖数 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\ \hline
ボーナス & 0 & 8 & 16 & 32 & 64 & 96 & 128 & 160 & 192 & 224\\ \hline
連鎖数 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & -\\ \hline
ボーナス & 256 & 288 & 320 & 352 & 384 & 416 & 448 & 480 & 512 & -\\ \hline
\end{tabular}
\end{center}
\end{table}

対戦では、算出されたスコアに応じて、対戦相手におじゃまぷよが降る。スコア70点がおじゃまぷよ1つに相当する。70点以下は切り捨てられ、次回に持ち越される。対象となるスコアは、これまでにおじゃまぷよに換算されていないすべてのスコアである。つまり、落下操作や全消しで加算されたスコアは、次のぷよの消去時におじゃまぷよの換算に使われる。

おじゃまぷよは連鎖終了後、相手が落下中のツモを設置した時点（相手が次のツモを引く前）で降る。おじゃまぷよの落下列は都度ランダムに選ばれる。ただし一度に複数のおじゃまぷよが落ちる際には、偏りが少なくなるように落下列が選ばれる。例えば6個以下のおじゃまぷよが2段以上で降ることはなく、おじゃまぷよ6個はすべての列に1つずつ降る。なお、一度に降るおじゃまぷよの数は30個（5段）が上限であり、一度おじゃまぷよが降ると次の一手が配される。上限を超えておじゃまぷよが存在する場合、1手のツモを置いたのちに再度降ってくることとなる。

自分のフィールドにおじゃまぷよが降るまでには、相手の連鎖発火から連鎖が終了し、さらに自分が1手を置くまでの猶予がある。相手からおじゃまぷよが送られている間に自分の連鎖を発火すると、おじゃまぷよの相殺ができる。相殺の後に得点の高かったプレイヤーが、相手にスコアの差分だけおじゃまぷよを降らすことができる。相殺の途中で相手の連鎖が終了しており、かつ相殺し切れなかった場合には、自分の連鎖終了後即座におじゃまぷよが降って来る。
%タイムテーブル

\section{ぷよぷよの対戦}
\subsection{対戦文化と大会}
%95年：全日本ぷよマスターズ大会、ばよえ～んツアー
ぷよぷよの対戦は、ゲームの発売以降長い間にわたって続いてきた。公式大会の歴史は1995年にまでさかのぼることができ、コンパイル主催で「全日本ぷよマスターズ大会」や「ばよえ～んツアー」などが大々的に行われていた。

%100本先取
公式大会以外にも、有志によるゲームセンターやインターネット上での大会は数多く行われてきた。特に上位プレイヤーは、ゲームセンターのAC版「ぷよぷよ通」で強さを競い、全日本一位の座を目指した。試合形式は100本先取戦とされ、時として200試合近くに及ぶ対戦によって勝敗がつけられた。
試合は非公式であったものの、十分に試合回数を重ねることで、偶然性を排した強者のランキングがコミュニティの中で共有されていた。

%対戦文化：大会、e-sports
近年では、eスポーツ人気の高まりに伴い、ぷよぷよの大会にスポンサーがついたり、上位プレイヤーがテレビ番組に出演する機会が増えている。2016年の主な大会では、セガ公式「ぷよぷよ」最強プレイヤー決定戦\ref{sega}、第5回アーケード版ぷよぷよ通S級リーグ\ref{Skyuu}、A級リーグ\ref{Akyuu}、統一王座戦\ref{touituouza}、Red Bull 5G 2016\ref{5g}などが開催された。このように、ぷよぷよの発売以降現在でも、対戦ゲームとしての人気は高い。実用のプレイAIを実装するにあたっては、対戦を念頭に置くことが重要である。

\subsection{対戦の基本的戦術}


AIの到達点としての戦術選択
小連鎖によるつぶし
先打ち有利=>発火催促
催促合戦、凝視、組み換え
（打つタイミング）



\section{連鎖}
定型と不定形
カウンター（耐える形）耐える、打つ、対応する、
大連鎖、連鎖の速さ

凝視しづらい連鎖形
早さ
合体、キーぷよ

\part{関連研究} \setcounter{section}{0}
\section{ゲームと楽しさ}
\section{楽しさに関するゲームAI}
%実用レベルの対戦相手に向けて：手加減、自然さ、人間の模倣、プレイヤーモデル
%ikeda
DDA
player modeling: yannnakakis
mario

\section{ぷよぷよAI}
\section{その他のパズルゲームAI}

\part{DQNによる学習} \setcounter{section}{0}
\section{とこぷよ}
\section{対戦}

\part{連鎖ポテンシャル法の改良} \setcounter{section}{0}
\section{探索深さの変更}
\section{全探索}
\section{途中での消去}
\section{ツモ選択と置き方選択の区別}

\part{人間の知識適用} \setcounter{section}{0}
\section{連鎖構築知識の抽出}
\section{ルール化と実装}
\section{結果と考察}

\part{結論} \setcounter{section}{0}
\section{研究成果}
\section{今後の課題}


\section*{参考文献}
\bibliographystyle{jplain}
\bibliography{ref}

\end{document}

